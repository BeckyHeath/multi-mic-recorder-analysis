# tidy label/ graph title name:
label = str_remove(as.character(i), file_directory)
label = str_remove(label,"/localized_")
label = str_remove(label,"_PostMortem")
label = str_remove(label,"Loc")
label = str_remove(label,".wav")
label = str_remove(label,"AdjG_")
j=j+1
tag = str_remove(label,".*_")
tag = gsub('[[:digit:]]+', '', tag)
# Set Graph Labels (Tags)
print(paste0("J =",tag))
if(tag == "pink"){
label_g = "Pink Noise"
} else if(tag=="bird"){
label_g = "Bird Song"
} else {
label_g ="??????"
}
tag =label_g
# Stop files that didn't catch any signals tripping out the loop
if(nrow(i_file) == 0){
next
}
i_file <- section_data(i_file)
o_plot <- Angle_Dif_Plots(i_file,tag,label)
assign(label, o_plot)
}
# Patchwork Plots This is to see all plots
plot <- `YelloGreen_bird01` | `YelloGreen_bird02` | `YelloGreen_bird03`
plot2 <- `YelloGreen_pink01`| `YelloGreen_pink02` | `YellowGreen_flipped_bird01`
plot/plot2
Plot <- `Yellow_bird01` | `Yellow_pink03`
Plot
plot2 <- `YelloGreen_bird02` | `YelloGreen_pink02`
plot | plot2
Plot | plot2
Plot <- `Yellow_bird01` | `Yellow_pink03` |`YelloGreen_bird02` | `YelloGreen_pink02`
Plot
plot <- ggplot(differences, aes(True.Azimuth, difference))+
ggtitle(label_g) +
geom_point(color = "Red", size =4, shape = 4, stroke = 1.5)+
geom_hline(yintercept=0)+
xlim(-180,180)+
ylim(-180,180)+
xlab("True Angle") +
#ylab("Angle Difference") +
#annotate("text", x = -150, y = 150, label = tag) +
theme_minimal()
plot/plot2
plot2 <- `YelloGreen_pink01`| `YelloGreen_pink02` | `YellowGreen_flipped_bird01`
plot/plot2
Plot <- `Yellow_bird01` | `Yellow_pink03` |`YelloGreen_bird02` | `YelloGreen_pink02`
Plot
########################################################################### .
# Script to Consolidate and graph field data volumes from Box
# Files generated either maually of through "MetadataFromBoxADD_OWN_DETAILS.m"
#
# Becky Heath
# r.heath18@imperial.ac.uk
#
# Spring 2022
##### Load Packages and set working directory #####
library(data.table)
library(dplyr)
library(tidyverse)
library(scales)
#### Load in files ####
# Set wd and initialise
setwd("C:/Users/becky/Desktop/Github/multi-mic-recorder-analysis/multi-mic-recorder-analysis")
# Load in Relevant data
recStatus <- read.csv("Data/Recorder_status.csv")
boxMeta <- read.csv("Data/BoxData_Apr14.csv")
###### join dataframes #####
# Consolidate Recorder Names so they're the same
# Convert the box directory names to just recorder colour
j=1
for(i in boxMeta$Recorder){
splitLabel <- strsplit(i, "_")
size <- length(splitLabel[[1]])
newLabel <- splitLabel[[1]][size]
newLabel <- tolower(newLabel)
boxMeta$Recorder[j] = newLabel
j=j+1
}
# Alighn DF properties to make sure they're compatible
names(recStatus)[1] <- "date"
boxMeta$Recorder <- as.factor(boxMeta$Recorder)
long <- melt(setDT(recStatus), id.vars = c("date"), variable.name = "Recorder")
# Join the dataframes
combinedDF <- full_join(long,boxMeta, by = c("date","Recorder"))
##### Get data about the recordings #####
# Finding totals accross the whole dataset:
recMeta <- data.frame(Recorder = character(),
Phase = character(),
recHours = numeric(),
recVol = numeric())
# Iterate through recorders and phases and get meta info
for(i in levels(as.factor(combinedDF$Recorder))){
recorder = i
singleRec <- combinedDF[combinedDF$Recorder == recorder,]
for(j in levels(as.factor(singleRec$value))){
phase = j
singlePhase <- singleRec[singleRec$value == phase,]
# Get Data
numHours = (sum(singlePhase$numFiles,na.rm = TRUE)*10)/60 # TEN MINUTE RECORDINGS
numHours = round(as.numeric(numHours), digits = 2) # 2 dp
dataVol = (sum(singlePhase$TotFileSizeMB, na.rm = TRUE))/1000
# Write to df
outLine <- data.frame(recorder, phase, numHours, dataVol)
recMeta <- rbind(recMeta, outLine)
}
}
# Get Totals
metaTotals <- data.frame(Phase = character(),
recHours = numeric(),
recVol = numeric())
for(i in levels(as.factor(recMeta$phase))){
phase = i
singlePhase <- recMeta[recMeta$phase == phase,]
recHours = sum(singlePhase$numHours, na.rm = TRUE)
recVol = sum(singlePhase$dataVol, na.rm = TRUE)#
outLine = data.frame(phase, recHours, recVol)
metaTotals = rbind(metaTotals,outLine)
}
# Finding the per diem recorder numbers
fieldPhases <- c("conifer","oak")
fieldRecs <- combinedDF[combinedDF$value == fieldPhases,]
# Graph the actual recording period
fullDep <- fieldRecs %>% filter(date >= "2021-08-25")
fullDep <- fullDep %>% filter(date <= "2022-01-22")
tot <- sum(fullDep$TotFileSizeMB,na.rm='True')
fullDep$date <- as.Date(fullDep$date)
cols <- c("darkgreen","gold1","yellowgreen","steelblue3")
Recs <-ggplot(fullDep, aes(x=date, y= numFiles,col = Recorder, fill = Recorder))+
scale_x_date(breaks = "1 month", minor_breaks = "1 week", labels = date_format("%B")) +
scale_colour_manual(values=cols) +
scale_fill_manual(values=cols) +
geom_point(shape = 4,alpha=0.5) +
geom_smooth(alpha = 0.1)+
scale_y_continuous(limits= c(0,150), oob = squish)+
labs(x= "Date")+
labs(y= "Daily Uploads (max 144)")+
theme_minimal()+
theme(legend.position = c(0.9,0.79))+
theme(legend.title=element_text(size=9),
legend.text=element_text(size=8))
Recs
rm(Recs)
# Present data in hours
fullDep$numFiles <- fullDep$numFiles/6
cols <- c("darkgreen","gold1","yellowgreen","steelblue3")
Recs <- ggplot(fullDep, aes(x=date, y= numFiles,col = Recorder, fill = Recorder))+
scale_x_date(breaks = "1 month", minor_breaks = "1 week", labels = date_format("%B")) +
scale_colour_manual(values=cols) +
scale_fill_manual(values=cols) +
geom_point(shape = 4,alpha=0.5) +
geom_smooth(alpha = 0.1)+
scale_y_continuous(limits= c(0,24), oob = squish)+
labs(x= "Date")+
labs(y= "Hours of Uploaded Data (daily)")+
theme_minimal()+
theme(legend.title=element_text(size=9),
legend.text=element_text(size=8))+
theme(legend.position = c(0.85,0.75))
Recs
rm(Recs)
########################################################################### .
# Scripts for Analysing Post Deployment Localisations
#
# Becky Heath
# r.heath18@imperial.ac.uk
#
# Autumn 2021/Spring 2022
##### Load Packages and set working directory #####
library(stringr)
library(ggplot2)
library(plyr)
library(patchwork)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
##### Define Test File Location #####
file_directory = "Data/postMortem/AllFiles/yellowOUT/Thresh27"
##### Define Functions #####
# Load in true values:
true <- read.csv("Data/Real_Location_Clean2.csv")
section_data <- function(df){
# Function to group the real data into distinct time periods??
# The recordings are then in groups to better compare real/predicted
#
# recallibrate start position to -180
# 30deg mismatch in the transfer function (See HARKTOOL5)
df$Start.azimuth <- df$Start.azimuth - 30 # do HARK config Correction
df$Start.azimuth <- df$Start.azimuth - 180 # do experiment orientation correction
# Correct for Angle Flip-over
df$Start.azimuth[df$Start.azimuth < -180] <- (df$Start.azimuth[df$Start.azimuth < -180] + 360)
# Numbers not divisible by 15 will be Removed
df$Start.time[df$Start.time < 7] <- 1  # Sweep Signal (ignored)
df$Start.time[df$Start.time > 14 & df$Start.time < 19] <- 15  # First Tone
df$Start.time[df$Start.time > 29 & df$Start.time < 31] <- 30  # Second Tone
df$Start.time[df$Start.time > 44 & df$Start.time < 46] <- 45  # Third Tone
df$Start.time[df$Start.time > 59 & df$Start.time < 61] <- 60  # Fourth Tone
df$Start.time[df$Start.time > 74.49 & df$Start.time < 77] <- 75  # Fifth Tone
return(df)
}
true_pred_plots <- function(df,tag,label){
# Creates plots showing true vs. predicted values
# Merge Data
df <- df[, c("Start.time", "Start.azimuth")]
names(df)[names(df) == "Start.azimuth"] <- "Predicted.Azimuth"
merge_df <- merge(df, true, by=c("Start.time"),all=TRUE)
names(merge_df)[names(merge_df) == "Start.azimuth"] <- "Real.Azimuth"
merge_df_er <- merge_df[complete.cases(merge_df),]
dif <- merge_df_er$Real.Azimuth - merge_df_er$Predicted.Azimuth
difLabel = paste("dif_",label, sep="")
assign(difLabel, dif, envir = .GlobalEnv)
error_data <- find_error(merge_df_er$Real.Azimuth, merge_df_er$Predicted.Azimuth)
printout <- paste0("\n###############\nFile:", label, "\nMean Error:", error_data[1],"\nSD:", error_data[2], "\nR_sq:", error_data[3])
cat(printout)
plot <- ggplot(merge_df, aes(Real.Azimuth, Predicted.Azimuth))+
ggtitle(label_g) +
geom_point(color = "Red", size =4, shape = 4, stroke = 1.5)+
geom_abline(color= "black", size = 0.6, alpha = 0.5) +
xlim(-180,180)+
ylim(-180,180)+
xlab("Predicted") +
ylab("True") +
annotate("text", x = -150, y = 150, label = tag) +
theme_minimal()
return(plot)
}
find_error <- function(x,y){
# finds the mean and sd of the error and r-sq where:
# x = real
# and y = predicted
dif <- y-x
dif = dif * dif
dif = sqrt(dif)
mean_val <- mean(dif)
sd_val <- sd(dif)
r_sq <- 1-sum((x-y)^2)/sum((x - mean(x))^2)
out <- c(mean_val,sd_val,r_sq)
return(out)
}
##### Generate Real vs. Predicted Plots ####
j=0
# Load in all the files you need:
for(i in list.dirs(file_directory, recursive = FALSE)){
path = paste(as.character(i),"sourcelist.csv", sep = "/")
i_file = read.csv(path, sep = "\t")
# Generate Label
# tidy label/ graph title name:
label = str_remove(as.character(i), file_directory)
label = str_remove(label,"/localized_")
label = str_remove(label,"_PostMortemLoc")
label = str_remove(label,".wav")
j=j+1
# Set Graph Labels (Tags)
tags = array(data=c('A','C','B','D'))
tag = tags[j]
print(paste0("J = ",j))
if(j == 1){
label_g = "Bird Song"
} else if(j==3){
label_g = "Pink Noise"
} else {
label_g =""
}
# Stop files that didn't catch any signals tripping out the loop
if(nrow(i_file) == 0){
next
}
i_file <- section_data(i_file)
o_plot <- true_pred_plots(i_file,tag,label)
assign(label, o_plot)
}
# Patchwork Plots
plot <- `Yellow_bird01` | `Yellow_bird02`
plot2 <- `Yellow_pink02` | `Yellow_pink03`
plot/plot2
########################################################################### .
# Scripts for Analysing Post Deployment Localisations
#
# Becky Heath
# r.heath18@imperial.ac.uk
#
# Autumn 2021/Spring 2022
##### Load Packages and set working directory #####
library(stringr)
library(ggplot2)
library(plyr)
library(patchwork)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
##### Define Test File Location #####
file_directory = "Data/postMortem/AllFiles/yellowOUT/Thresh27"
##### Define Functions #####
# Load in true values:
true <- read.csv("Data/Real_Location_Clean2.csv")
section_data <- function(df){
# Function to group the real data into distinct time periods??
# The recordings are then in groups to better compare real/predicted
#
# recallibrate start position to -180
# 30deg mismatch in the transfer function (See HARKTOOL5)
df$Start.azimuth <- df$Start.azimuth - 30 # do HARK config Correction
df$Start.azimuth <- df$Start.azimuth - 180 # do experiment orientation correction
# Correct for Angle Flip-over
df$Start.azimuth[df$Start.azimuth < -180] <- (df$Start.azimuth[df$Start.azimuth < -180] + 360)
# Numbers not divisible by 15 will be Removed
df$Start.time[df$Start.time < 7] <- 1  # Sweep Signal (ignored)
df$Start.time[df$Start.time > 14 & df$Start.time < 19] <- 15  # First Tone
df$Start.time[df$Start.time > 29 & df$Start.time < 31] <- 30  # Second Tone
df$Start.time[df$Start.time > 44 & df$Start.time < 46] <- 45  # Third Tone
df$Start.time[df$Start.time > 59 & df$Start.time < 61] <- 60  # Fourth Tone
df$Start.time[df$Start.time > 74.49 & df$Start.time < 77] <- 75  # Fifth Tone
return(df)
}
Angle_Dif_Plots <- function(df,tag,label){
# Creates plots showing true vs. prediced values
# Merge Data
df <- df[, c("Start.time", "Start.azimuth")]
names(df)[names(df) == "Start.azimuth"] <- "Predicted.Azimuth"
merge_df <- merge(df, true, by=c("Start.time"),all=TRUE)
names(merge_df)[names(merge_df) == "Start.azimuth"] <- "Real.Azimuth"
merge_df_er <- merge_df[complete.cases(merge_df),]
differences <- getDifferences(merge_df_er)
differences <- as.data.frame(differences)
names(differences)[names(differences) == "x"] <- "True.Azimuth"
plot <- ggplot(differences, aes(True.Azimuth, difference))+
ggtitle(label_g) +
geom_point(color = "Red", size =4, shape = 4, stroke = 1.5)+
geom_hline(yintercept=0)+
xlim(-180,180)+
ylim(-180,180)+
xlab("True Angle") +
#ylab("Angle Difference") +
#annotate("text", x = -150, y = 150, label = tag) +
theme_minimal()
plot
return(plot)
}
getDifferences <- function(df){
# Finds difference (accounting for 180 + 5 = -175)!
# It then returns an array of true v. pred for the
# difference of smallest magnitude
#
#
# df = dataframe containing true vs. pred data =
# Seperate true and pred
x <- df$Real.Azimuth
y <- df$Predicted.Azimuth
# Calculate Differences
dif <- y-x
dif1 <- y - x - 360
dif2 <- y - x + 360
# Find Smallest
difference <- apply(cbind(dif,dif1,dif2), 1, function(z) z[which.min(abs(z))])
outDf <- cbind(x,difference)
names(outDf)[names(outDf) == "outDF"] <- "True.Azimuth"
return(outDf)
}
##### Generate Real vs. Predicted Plots ####
j=0
# Load in all the files you need:
for(i in list.dirs(file_directory, recursive = FALSE)){
path = paste(as.character(i),"sourcelist.csv", sep = "/")
i_file = read.csv(path, sep = "\t")
# Generate Label
# tidy label/ graph title name:
label = str_remove(as.character(i), file_directory)
label = str_remove(label,"/localized_")
label = str_remove(label,"_PostMortem")
label = str_remove(label,"Loc")
label = str_remove(label,".wav")
label = str_remove(label,"AdjG_")
j=j+1
tag = str_remove(label,".*_")
tag = gsub('[[:digit:]]+', '', tag)
# Set Graph Labels (Tags)
print(paste0("J =",tag))
if(tag == "pink"){
label_g = "Pink Noise"
} else if(tag=="bird"){
label_g = "Bird Song"
} else {
label_g ="??????"
}
tag =label_g
# Stop files that didn't catch any signals tripping out the loop
if(nrow(i_file) == 0){
next
}
i_file <- section_data(i_file)
o_plot <- Angle_Dif_Plots(i_file,tag,label)
assign(label, o_plot)
}
# Patchwork Plots This is to see all plots
plot <- `YelloGreen_bird01` | `YelloGreen_bird02` | `YelloGreen_bird03`
plot2 <- `YelloGreen_pink01`| `YelloGreen_pink02` | `YellowGreen_flipped_bird01`
plot/plot2
Plot <- `Yellow_bird01` | `Yellow_pink03` |`YelloGreen_bird02` | `YelloGreen_pink02`
Plot
Plot <- `Yellow_bird01` | `Yellow_pink03`
Plot
########################################################################### .
# Scripts for Analysing the Sweeps
#
# Becky Heath
# r.heath18@imperial.ac.uk
#
# Autumn 2021
##### Load Packages and set working directory #####
library(stringr)
library(ggplot2)
library(plyr)
library(patchwork)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
##### Define Test File Location #####
file_directory = "Data/Lab_Localisation/dev2_clean_outputs/"
##### Define Functions #####
# Load in true values:
true <- read.csv("Data/Real_Location_Clean.csv")
section_data <- function(df){
# Function to group the real data into distinct time periods??
# The recordings are then in groups to better compare real/predicted
#
# recallibrate start position to -180
# 30deg mismatch in the transfer function (See HARKTOOL5)
df$Start.azimuth <- df$Start.azimuth - 30
# Numbers not divisible by 15 will be Removed
df$Start.time[df$Start.time < 7] <- 1  # Sweep Signal (ignored)
df$Start.time[df$Start.time > 15 & df$Start.time < 20] <- 15  # First Tone
df$Start.time[df$Start.time > 30 & df$Start.time < 35] <- 30  # Second Tone
df$Start.time[df$Start.time > 45 & df$Start.time < 50] <- 45  # Third Tone
df$Start.time[df$Start.time > 60 & df$Start.time < 65] <- 60  # Fourth Tone
df$Start.time[df$Start.time > 75 & df$Start.time < 80] <- 75  # Fifth Tone
return(df)
}
true_pred_plots <- function(df,tag,label){
# Creates plots showing true vs. predicted values
# Merge Data
df <- df[, c("Start.time", "Start.azimuth")]
df <- rename(df, c("Start.azimuth" = "Predicted.Azimuth"))
merge_df <- merge(df, true, by=c("Start.time"),all=TRUE)
merge_df <- rename(merge_df, c("Start.azimuth" = "Real.Azimuth"))
merge_df_er <- merge_df[complete.cases(merge_df),]
dif <- merge_df_er$Real.Azimuth - merge_df_er$Predicted.Azimuth
difLabel = paste("dif_",label, sep="")
assign(difLabel, dif, envir = .GlobalEnv)
error_data <- find_error(merge_df_er$Real.Azimuth, merge_df_er$Predicted.Azimuth)
printout <- paste0("\n###############\nFile:", label, "\nMean Error:", error_data[1],"\nSD:", error_data[2], "\nR_sq:", error_data[3])
cat(printout)
plot <- ggplot(merge_df, aes(Real.Azimuth, Predicted.Azimuth))+
ggtitle(label_g) +
geom_point(color = "Red", size =4, shape = 4, stroke = 1.5)+
geom_abline(color= "black", size = 0.6, alpha = 0.5) +
xlim(-180,180)+
ylim(-180,180)+
xlab("Predicted") +
ylab("True") +
annotate("text", x = -150, y = 150, label = tag) +
theme_minimal()
return(plot)
}
find_error <- function(x,y){
# finds the mean and sd of the error and r-sq where:
# x = real
# and y = predicted
dif <- y-x
dif = dif * dif
dif = sqrt(dif)
mean_val <- mean(dif)
sd_val <- sd(dif)
r_sq <- 1-sum((x-y)^2)/sum((x - mean(x))^2)
out <- c(mean_val,sd_val,r_sq)
return(out)
}
##### Generate Real vs. Predicted Plots ####
j=0
# Load in all the files you need:
for(i in list.dirs(file_directory, recursive = FALSE)){
path = paste(as.character(i),"sourcelist.csv", sep = "/")
i_file = read.csv(path, sep = "\t")
# Generate Label
# tidy label/ graph title name:
label = str_remove(as.character(i), file_directory)
label = str_remove(label,"/localized_")
label = str_remove(label,".wav")
j=j+1
# Set Graph Labels (Tags)
tags = array(data=c('A','C','B','D'))
tag = tags[j]
print(paste0("J = ",j))
if(j == 1){
label_g = "Not Weatherproofed"
} else if(j==3){
label_g = "Weatherproofed"
} else {
label_g =""
}
# Stop files that didn't catch any signals tripping out the loop
if(nrow(i_file) == 0){
next
}
i_file <- section_data(i_file)
o_plot <- true_pred_plots(i_file,tag,label)
assign(label, o_plot)
}
# Patchwork Plots
plot <- `1a_pinknoise_N_2`| `5a_pinknoise_Y_2`
plot2 <- `1b_bird_N_2` | `5b_bird_Y_2`
plot/plot2
